{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "DELTA_MEAN = 64\n",
    "REVIEW_MEAN = 1041\n",
    "REVIEW_MEDIAN = 904\n",
    "    \n",
    "\n",
    "df_train = pd.read_csv('main_task.csv')\n",
    "df_test = pd.read_csv('kaggle_task.csv')\n",
    "\n",
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_time(row):\n",
    "    match = re.findall('\\d\\d/\\d\\d/\\d\\d\\d\\d', str(row['Reviews']))\n",
    "    fake = pd.to_datetime('10/25/2017', format='%m/%d/%Y')\n",
    "    doomsday = pd.to_datetime('03/18/2020', format='%m/%d/%Y')\n",
    "    if len(match) == 0:\n",
    "        return [fake, fake, REVIEW_MEDIAN]\n",
    "    elif len(match) == 1:\n",
    "        return [pd.to_datetime(match[0], format='%m/%d/%Y'), fake, \\\n",
    "                (doomsday - pd.to_datetime(match[0], format='%m/%d/%Y')).days]\n",
    "    t1 = pd.to_datetime(match[0],format='%m/%d/%Y')\n",
    "    t2 = pd.to_datetime(match[1], format='%m/%d/%Y')\n",
    "    if t1 > t2:\n",
    "        t3 = doomsday - t1\n",
    "    else:\n",
    "        t3 = doomsday - t2\n",
    "    return [t1, t2, t3.days]\n",
    "\n",
    "def create_dict(df):\n",
    "    cuisine_dict = {}\n",
    "    cuisine_freq = {}\n",
    "    idx = 0 \n",
    "    for each in df['Cuisine Style']:\n",
    "        for cuisine in each:\n",
    "            if not cuisine in cuisine_dict:\n",
    "                cuisine_dict[cuisine] = idx\n",
    "                cuisine_freq[cuisine] = 1\n",
    "                idx += 1\n",
    "            else:\n",
    "                cuisine_freq[cuisine] += 1\n",
    "    return [cuisine_dict, cuisine_freq]\n",
    "\n",
    "def dummy_venue(row):\n",
    "    temp = [0,0,0,0,0,0,0]\n",
    "    bar_venue = ['Bar', 'Pub', 'Wine Bar', 'Brew Pub']\n",
    "    fast_venue = ['Pizza', 'Fast Food', 'Street Food']\n",
    "    cafe_venue = ['Cafe', 'Gastropub', 'Diner']\n",
    "    vegan_venue = ['Vegetarian Friendly', 'Vegan Options', 'Gluten Free Options']\n",
    "    meat_venue = ['Grill', 'Steakhouse', 'Barbecue']\n",
    "    seafood_venue = ['Seafood', 'Sushi']\n",
    "    for each in row['Cuisine Style']:\n",
    "        if each == 'NaN':\n",
    "            temp[0] = 1\n",
    "        elif each in bar_venue:\n",
    "            temp[1] = 1\n",
    "        elif each in fast_venue:\n",
    "            temp[2] = 1\n",
    "        elif each in cafe_venue:\n",
    "            temp[3] = 1\n",
    "        elif each in vegan_venue:\n",
    "            temp[4] = 1\n",
    "        elif each in meat_venue:\n",
    "            temp[5] = 1\n",
    "        else:\n",
    "            temp[6] = 1\n",
    "    return pd.Series(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(data['City']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    \n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### 1. Предобработка ############################################################## \n",
    "    # убираем не нужные для модели признаки\n",
    "    df_output.drop(['Restaurant_id','ID_TA'], axis = 1, inplace=True)\n",
    "    \n",
    "    # ################### 2. NAN ############################################################## \n",
    "    # Далее заполняем пропуски, вы можете попробовать заполнением средним или средним по городу и тд...\n",
    "\n",
    "    # тут ваш код по обработке NAN\n",
    "    # ....\n",
    "    \n",
    "    df_output['Cuisine Style_isNAN'] = pd.isna(df_output['Cuisine Style']).astype('uint8')\n",
    "    df_output['Price Range_isNAN'] = pd.isna(df_output['Price Range']).astype('uint8')\n",
    "    df_output['Number_of_Reviews_isNAN'] = pd.isna(df_output['Number of Reviews']).astype('uint8')\n",
    "    df_output['Reviews_isNAN'] = pd.isna(df_output['Reviews']).astype('uint8')\n",
    "\n",
    "    # Далее заполняем пропуски\n",
    "    \n",
    "    df_output['Number of Reviews'].fillna(0, inplace=True)\n",
    "    df_output['Price Range'].fillna('$$ - $$$', inplace=True)\n",
    "    df_output['Cuisine Style'].fillna('NaN', inplace=True)\n",
    "    df_output['Reviews'].fillna('NaN', inplace=True)\n",
    "    \n",
    "    print(df_output.info())\n",
    "    # ################### 3. Encoding ############################################################## \n",
    "    \n",
    "    df_output = pd.get_dummies(df_output, columns=[ 'City',], dummy_na=True)\n",
    "    #Кодирование городов методом Label Encoding\n",
    "    #le = LabelEncoder()\n",
    "    #df_output['City Code'] = le.fit_transform(df_input['City'])\n",
    "    \n",
    "    price_range_dict = {\n",
    "    '$': 1,\n",
    "    '$$ - $$$': 2,\n",
    "    '$$$$': 3\n",
    "    }\n",
    "    df_output['Price Range'] = df_output['Price Range'].map(price_range_dict)\n",
    "    \n",
    "    print(df_output.info())\n",
    "    # ################### 4. Feature Engineering ####################################################\n",
    "    # тут ваш код на генерацию новых фичей\n",
    "    # ....\n",
    "    df_output['Ranking_norm'] = df_input['Ranking'] / df_input['City'].map(df_input.groupby(['City'])['Ranking'].max())\n",
    "    \n",
    "    # создание признака \"население городов\"\n",
    "    population = {'Paris': 2190327, 'Stockholm': 961609, 'London': 8908081, 'Berlin': 3644826, 'Munich': 1456039, \n",
    "                  'Oporto': 237591,\n",
    "                  'Milan': 1378689,'Bratislava': 432864, 'Vienna': 1821582, 'Rome': 4355725, \n",
    "                  'Barcelona': 1620343, 'Madrid': 3223334,\n",
    "                  'Dublin': 1173179,'Brussels': 179277, 'Zurich': 4+28737, 'Warsaw': 1758143, \n",
    "                  'Budapest': 1752286, 'Copenhagen': 615993,\n",
    "                  'Amsterdam': 857713,'Lyon': 506615, 'Hamburg': 1841179,'Lisbon': 505526, \n",
    "                  'Prague': 1301132, 'Oslo': 673469,\n",
    "                  'Helsinki': 643272,'Edinburgh': 488100,'Geneva': 200548, 'Ljubljana': 284355,\n",
    "                  'Athens': 664046, 'Luxembourg': 115227,\n",
    "                  'Krakow': 769498}\n",
    "    \n",
    "    df_output['Population'] = df_input['City'].map(population)\n",
    "    df_output['review_norm'] = df_output['Number of Reviews']/df_output['Population']\n",
    "    \n",
    "    #Количеcтво ресторанов на город, берем по максимальному значению Ranking\n",
    "    df_output['count_city_venue'] = df_input['City'].map(df_input.groupby(['City'])['Ranking'].max().to_dict())\n",
    "    \n",
    "    df_output['Pop_Rest'] = df_input['City'].map(population) / df_output['count_city_venue']\n",
    "    df_output['Rev_Rest'] = df_output['Number of Reviews'] / df_output['Pop_Rest']\n",
    "    \n",
    "    df_temp = df_output.apply(review_time, axis=1, result_type='expand')\n",
    "    fake = pd.to_datetime('10/25/2017',  format='%m/%d/%Y')\n",
    "    \n",
    "\n",
    "    df_output['delta'] = df_temp.apply(lambda x: abs((x[0]-x[1])).\\\n",
    "                                       days if not x[0] == fake or not x[1] == fake else DELTA_MEAN, axis=1)\n",
    "    \n",
    "    df_output['is_good'] = df_input['Reviews'].apply(\\\n",
    "    lambda x: 0 if pd.isna(re.search(\"Good|good|excellent|Excellent|awesome|Awesome|Best|best|Nice|nice\", str(x))) else 1)\n",
    "    \n",
    "    #City is capital?\n",
    "    \n",
    "    capitals = ['London', 'Paris', 'Madrid', 'Berlin', 'Rome', 'Prague', \n",
    "            'Lisbon', 'Vienna', 'Amsterdam', 'Brussels', 'Stockholm', \n",
    "            'Budapest', 'Warsaw', 'Dublin', 'Copenhagen', 'Athens', \n",
    "            'Oslo', 'Helsinki', 'Bratislava', 'Luxembourg', 'Ljubljana','Edinburgh']\n",
    "    \n",
    "    df_output['City Cap'] = df_input['City'].apply(lambda x: 1 if x in capitals else 0)\n",
    "    \n",
    "    #df_output['rest_id'] = df_input['Restaurant_id'].map(lambda x: int(x[3:]))\n",
    "    df_output['id_ta'] = df_input['ID_TA'].map(lambda x: int(x[1:]))\n",
    "    \n",
    "  \n",
    "    #cuisine \n",
    "     \n",
    "    df_output['Cuisine Style'] = df_output['Cuisine Style'].apply(lambda x: re.findall('\\w+\\s*\\w+\\s*\\w+', str(x)))\n",
    "    [cuisine_dict, cuisine_freq] = create_dict(df_output)\n",
    "    df_output['cuisine count'] = df_output['Cuisine Style'].map(lambda x: len(x))\n",
    "    df_output['max_cuisine_idx'] = df_output.apply(lambda row: max([cuisine_dict[x] for x in row['Cuisine Style']]), axis=1)\n",
    "    \n",
    "    dummy_cuisine = df_output.apply(dummy_venue, axis=1)\n",
    "    dummy_cuisine.columns = ['boom', 'bar', 'cafe', 'fastfood', 'vegan', 'meat', 'national']\n",
    "    \n",
    "    df_output = df_output.join(dummy_cuisine)\n",
    "    \n",
    "    ################### 5. Clean #################################################### \n",
    "    # убираем признаки которые еще не успели обработать, \n",
    "    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n",
    "    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n",
    "    df_output.drop(object_columns, axis = 1, inplace=True)\n",
    "    \n",
    "    #Удаляем столбцы в поисках оптимальных сочетаний\n",
    "    to_drop = ['City_nan']\n",
    "    df_output.drop(to_drop, axis = 1, inplace=True)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   City                     50000 non-null  object \n",
      " 1   Cuisine Style            50000 non-null  object \n",
      " 2   Ranking                  50000 non-null  float64\n",
      " 3   Price Range              50000 non-null  object \n",
      " 4   Number of Reviews        50000 non-null  float64\n",
      " 5   Reviews                  50000 non-null  object \n",
      " 6   URL_TA                   50000 non-null  object \n",
      " 7   sample                   50000 non-null  int64  \n",
      " 8   Rating                   50000 non-null  float64\n",
      " 9   Cuisine Style_isNAN      50000 non-null  uint8  \n",
      " 10  Price Range_isNAN        50000 non-null  uint8  \n",
      " 11  Number_of_Reviews_isNAN  50000 non-null  uint8  \n",
      " 12  Reviews_isNAN            50000 non-null  uint8  \n",
      "dtypes: float64(3), int64(1), object(5), uint8(4)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 44 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Cuisine Style            50000 non-null  object \n",
      " 1   Ranking                  50000 non-null  float64\n",
      " 2   Price Range              50000 non-null  int64  \n",
      " 3   Number of Reviews        50000 non-null  float64\n",
      " 4   Reviews                  50000 non-null  object \n",
      " 5   URL_TA                   50000 non-null  object \n",
      " 6   sample                   50000 non-null  int64  \n",
      " 7   Rating                   50000 non-null  float64\n",
      " 8   Cuisine Style_isNAN      50000 non-null  uint8  \n",
      " 9   Price Range_isNAN        50000 non-null  uint8  \n",
      " 10  Number_of_Reviews_isNAN  50000 non-null  uint8  \n",
      " 11  Reviews_isNAN            50000 non-null  uint8  \n",
      " 12  City_Amsterdam           50000 non-null  uint8  \n",
      " 13  City_Athens              50000 non-null  uint8  \n",
      " 14  City_Barcelona           50000 non-null  uint8  \n",
      " 15  City_Berlin              50000 non-null  uint8  \n",
      " 16  City_Bratislava          50000 non-null  uint8  \n",
      " 17  City_Brussels            50000 non-null  uint8  \n",
      " 18  City_Budapest            50000 non-null  uint8  \n",
      " 19  City_Copenhagen          50000 non-null  uint8  \n",
      " 20  City_Dublin              50000 non-null  uint8  \n",
      " 21  City_Edinburgh           50000 non-null  uint8  \n",
      " 22  City_Geneva              50000 non-null  uint8  \n",
      " 23  City_Hamburg             50000 non-null  uint8  \n",
      " 24  City_Helsinki            50000 non-null  uint8  \n",
      " 25  City_Krakow              50000 non-null  uint8  \n",
      " 26  City_Lisbon              50000 non-null  uint8  \n",
      " 27  City_Ljubljana           50000 non-null  uint8  \n",
      " 28  City_London              50000 non-null  uint8  \n",
      " 29  City_Luxembourg          50000 non-null  uint8  \n",
      " 30  City_Lyon                50000 non-null  uint8  \n",
      " 31  City_Madrid              50000 non-null  uint8  \n",
      " 32  City_Milan               50000 non-null  uint8  \n",
      " 33  City_Munich              50000 non-null  uint8  \n",
      " 34  City_Oporto              50000 non-null  uint8  \n",
      " 35  City_Oslo                50000 non-null  uint8  \n",
      " 36  City_Paris               50000 non-null  uint8  \n",
      " 37  City_Prague              50000 non-null  uint8  \n",
      " 38  City_Rome                50000 non-null  uint8  \n",
      " 39  City_Stockholm           50000 non-null  uint8  \n",
      " 40  City_Vienna              50000 non-null  uint8  \n",
      " 41  City_Warsaw              50000 non-null  uint8  \n",
      " 42  City_Zurich              50000 non-null  uint8  \n",
      " 43  City_nan                 50000 non-null  uint8  \n",
      "dtypes: float64(3), int64(2), object(3), uint8(36)\n",
      "memory usage: 4.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_preproc = preproc_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "\n",
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели\n",
    "\n",
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
